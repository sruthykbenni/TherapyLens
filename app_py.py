# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/156I8oQTGq7BMMSRNGLk9KOm_KSTkSfy4
"""

import streamlit as st
import pandas as pd
import json
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, T5ForConditionalGeneration
from bertopic import BERTopic
from langdetect import detect
import nltk

nltk.download('punkt')

st.set_page_config(layout="wide")
st.title("ðŸ§  Sentiment & Emotion Tracker from Journals")

# Upload JSON file
uploaded_file = st.file_uploader("ðŸ“„ Upload your 'intents.json' journal file", type="json")

if uploaded_file is not None:
    data = json.load(uploaded_file)
    entries = []
    for intent in data['intents']:
        for pattern in intent['patterns']:
            entries.append({'text': pattern, 'tag': intent.get('tag', 'unknown')})
    df = pd.DataFrame(entries)
    df['session'] = (df.index // 10) + 1

    # Detect language and filter only English
    df['language'] = df['text'].apply(lambda x: detect(x))
    df = df[df['language'] == 'en']

    st.success("âœ… Data loaded and filtered for English entries.")

    # Sentiment & Emotion Pipelines
    sentiment_pipeline = pipeline("sentiment-analysis")
    emotion_pipeline = pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base", top_k=1)

    with st.spinner("ðŸ” Performing sentiment and emotion analysis..."):
        df['sentiment_result'] = df['text'].apply(lambda x: sentiment_pipeline(x)[0])
        df['sentiment'] = df['sentiment_result'].apply(lambda x: x['label'])
        df['sentiment_score'] = df['sentiment_result'].apply(lambda x: x['score'])

        df['emotion_result'] = df['text'].apply(lambda x: emotion_pipeline(x)[0][0])
        df['emotion'] = df['emotion_result'].apply(lambda x: x['label'])
        df['emotion_score'] = df['emotion_result'].apply(lambda x: x['score'])

    def categorize_intensity(score):
        if score >= 0.85: return "Extreme"
        elif score >= 0.65: return "Strong"
        elif score >= 0.4: return "Moderate"
        else: return "Mild"
    df['emotion_intensity'] = df['emotion_score'].apply(categorize_intensity)

    st.success("âœ… Emotion intensity categorized.")

    # BERTopic for topic modeling
    with st.spinner("ðŸ§  Extracting topics with BERTopic..."):
        topic_model = BERTopic()
        topics, _ = topic_model.fit_transform(df['text'])
        df['topic'] = topics

    # Summarization with T5
    tokenizer = T5Tokenizer.from_pretrained("t5-small")
    model = T5ForConditionalGeneration.from_pretrained("t5-small")

    def summarize(text):
        input_text = "summarize: " + text
        input_ids = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)
        summary_ids = model.generate(input_ids, max_length=50, min_length=10, num_beams=4, early_stopping=True)
        return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    df['session_text'] = df.groupby('session')['text'].transform(lambda x: " ".join(x))
    df['session_summary'] = df.groupby('session')['session_text'].transform(lambda x: summarize(x.iloc[0]) if len(x.iloc[0].split()) > 20 else "Too short for summary")

    # Alerts
    def alert_flag(row):
        if row['emotion'] in ['anger', 'sadness'] and row['emotion_score'] > 0.8:
            return "ALERT"
        return "NORMAL"
    df['alert'] = df.apply(alert_flag, axis=1)
    df['consec_alert'] = df['alert'].eq('ALERT').astype(int)
    df['consec_alert'] = df['consec_alert'].groupby(df['session']).transform('sum')
    df['session_alert'] = df['consec_alert'].apply(lambda x: 'CRITICAL' if x >= 3 else 'OK')

    # Visualizations
    st.subheader("ðŸ“ˆ Sentiment and Emotion Trends")

    sentiment_trend = df.groupby("session")["sentiment"].value_counts().unstack().fillna(0)
    emotion_trend = df.groupby("session")["emotion"].value_counts().unstack().fillna(0)

    st.write("### Sentiment Trend Across Sessions")
    st.bar_chart(sentiment_trend)

    st.write("### Emotion Trend Across Sessions")
    st.bar_chart(emotion_trend)

    st.write("### Word Cloud of Journal Texts")
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(" ".join(df['text']))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    st.pyplot(plt)

    st.subheader("ðŸ“‹ Session Summaries and Alerts")
    st.dataframe(df[['session', 'session_summary', 'session_alert']].drop_duplicates(), use_container_width=True)

    # CSV Export
    st.download_button("ðŸ“¥ Download Processed CSV", df.to_csv(index=False), file_name="therapy_emotion_analysis_advanced.csv", mime="text/csv")